<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>📚论文 on π1l4r_のblog</title>
        <link>https://pillar23.github.io/post/thesis/</link>
        <description>Recent content in 📚论文 on π1l4r_のblog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>pill4r</copyright>
        <lastBuildDate>Sat, 02 Mar 2024 20:19:11 +0800</lastBuildDate><atom:link href="https://pillar23.github.io/post/thesis/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>MAGIC</title>
        <link>https://pillar23.github.io/p/magic/</link>
        <pubDate>Sat, 02 Mar 2024 20:19:11 +0800</pubDate>
        
        <guid>https://pillar23.github.io/p/magic/</guid>
        <description>&lt;p&gt;文章可以在&lt;a class=&#34;link&#34; href=&#34;https://doi.org/10.48550/arXiv.2310.09831&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这里&lt;/a&gt;获取&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;APT攻击越来越成为普遍的威胁，然而，以前的工作表现出几个缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;需要包含攻击的数据和APT的先验知识&lt;/li&gt;
&lt;li&gt;无法提取隐藏在来源图中的丰富上下文信息&lt;/li&gt;
&lt;li&gt;由于其令人望而却步的计算开销和内存消耗而变得不切实际。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文介绍一种自监督APT检测方法MAGIC，能够在不同级别的监督下进行多粒度检测。利用掩码图表示学习对良性系统实体和行为进行建模，对来源图进行高效的深度特征提取和结构抽象。通过异常值检测方法检测异常系统行为，MAGIC 能够执行系统实体级和批处理日志级 APT 检测。&lt;/p&gt;
&lt;p&gt;MAGIC是专门为处理概念漂移而设计的，具有模型适配机制，并成功应用于通用条件和检测场景。我们在三个广泛使用的数据集上评估了MAGIC，包括真实世界和模拟攻击。评估结果表明，MAGIC在所有场景中都取得了令人鼓舞的检测结果，并且在性能开销方面比最先进的APT检测方法具有巨大的优势。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;高级持续性威胁（APTs）是由熟练的攻击者进行的蓄意和复杂的网络攻击，对企业和机构都构成巨大威胁。大多数 APT 都涉及零日漏洞，并且由于其隐蔽性和多变性而特别难以检测。&lt;/p&gt;
&lt;p&gt;最近关于APT检测的工作利用数据来源进行APT检测。数据来源将审计日志转换为来源图，从审计日志中提取丰富的上下文信息，为细粒度的因果关系分析和 APT 检测提供完美的平台。&lt;/p&gt;
&lt;p&gt;早期工作基于典型或特定的 APT 模式&lt;strong&gt;构建规则&lt;/strong&gt;，并将审计日志与这些规则进行匹配，以检测潜在的 APT。&lt;/p&gt;
&lt;p&gt;最近的一些工作采用&lt;strong&gt;统计异常检测&lt;/strong&gt;方法来检测APT，这些APT侧重于不同的来源图元素，例如系统实体、交互和社区。&lt;/p&gt;
&lt;p&gt;最近的研究基于&lt;strong&gt;深度学习的方法&lt;/strong&gt;。他们利用各种深度学习 （DL） 技术对 APT 模式或系统行为进行建模，并以分类或异常检测方式执行 APT 检测。&lt;/p&gt;
&lt;p&gt;虽然这些现有方法已经证明了它们能够以合理的准确性检测 APT，但它们遇到了以下挑战的各种组合：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;监督方法存在缺乏数据 （LOD） 问题，因为它们需要有关 APT 的先验知识（即攻击模式或包含攻击的日志）。此外，当面对他们没有接受过处理培训的新型 APT 时，这些方法特别容易受到攻击。&lt;/li&gt;
&lt;li&gt;基于统计的方法只需要良性数据即可发挥作用，但无法提取审计日志中埋藏的复杂良性活动的深层语义和相关性，导致&lt;strong&gt;误报率高。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;基于深度学习的方法，特别是基于序列和基于图的方法，以&lt;strong&gt;沉重的计算开销&lt;/strong&gt;为代价，取得了可观的有效性，使其在实际检测场景中不切实际&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在本文中，我们通过引入MAGIC来解决上述三个问题，MAGIC是一种新颖的自监督APT检测方法，它利用掩码图表示学习和简单的异常值检测方法从海量审计日志中识别关键攻击系统实体。MAGIC首先通过简单而通用的步骤从审计日志中构建出处图。然后，MAGIC使用图表示模块，该模块通过以自我监督的方式合并图特征和结构信息来获得嵌入。该模型建立在图形掩蔽自编码器[19]之上，在掩蔽特征重建和基于样本的结构重建的共同监督下。采用无监督异常值检测方法对计算出的嵌入进行分析，并得到最终的检测结果。&lt;/p&gt;
&lt;p&gt;MAGIC首先通过简单而通用的步骤从审计日志中构建出处图。然后，MAGIC使用图表示模块，该模块通过以自我监督的方式合并图特征和结构信息来获得嵌入。该模型建立在图形掩蔽自编码器之上，在掩蔽特征重建和基于样本的结构重建的共同监督下。采用无监督异常值检测方法对计算出的嵌入进行分析，并得到最终的检测结果。&lt;/p&gt;
&lt;p&gt;MAGIC 旨在灵活且可扩展。根据应用程序背景，MAGIC 能够执行多粒度检测，即检测批处理日志中是否存在 APT 或定位实体级对手。虽然 MAGIC 旨在执行 APT 检测而不会受到攻击包含数据，但它非常适合半监督和完全监督的情况。此外，MAGIC还包含一个可选的模型适配机制，为其用户提供反馈渠道。这样的反馈对于MAGIC进一步提高性能、对抗概念漂移和减少误报非常重要。&lt;/p&gt;
&lt;p&gt;我们在三个不同的 APT 攻击数据集上评估了MAGIC的性能和开销：DARPA Transparent Computing E3 数据集、StreamSpot 数据集和 Unicorn Wget 数据集。DARPA 数据集包含真实世界的攻击，而 StreamSpot 和 Unicorn Wget 数据集则在受控环境中完全模拟。评估结果表明，MAGIC 能够以 97.26% 的准确率和 99.91% 的召回率执行实体级 APT 检测，并且开销最小，对内存的要求更低，并且比最先进的方法快得多&lt;/p&gt;
&lt;p&gt;contribution总结&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出了MAGIC，这是一种基于掩码图表示学习和异常值检测方法的通用APT检测方法，能够对海量审计日志进行多粒度检测。&lt;/li&gt;
&lt;li&gt;通过扩展的图形掩码自动编码器将计算开销降至最低，从而确保 MAGIC 的实用性，即使在狭小的条件下，也能在可接受的时间内完成训练和检测。&lt;/li&gt;
&lt;li&gt;通过各种努力确保MAGIC的普遍性。我们利用掩码图表示学习和异常值检测方法，使 MAGIC 能够在不同的监管级别、不同的检测粒度和来自不同来源的审计日志下进行精确检测。&lt;/li&gt;
&lt;li&gt;在三个广泛使用的数据集上评估了 MAGIC，涉及真实世界和模拟的 APT 攻击。评估结果表明，MAGIC检测的APTs具有良好的结果和最小的计算开销。&lt;/li&gt;
&lt;li&gt;提供 MAGIC 的开源实现，以造福社区未来的研究，并鼓励进一步改进我们的方法。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;攻击场景&#34;&gt;攻击场景&lt;/h3&gt;
&lt;p&gt;在这里，我们提供了我们在整篇文章中使用的 APT 场景的详细说明。带有 Drakon Dropper 的 Pine 后门是来自 DARPA Engagement 3 Trace 数据集的 APT 攻击 [20]。在攻击过程中，攻击者构建恶意可执行文件 （/tmp/tcexec） 并通过网络钓鱼电子邮件将其发送到目标主机。然后，用户会无意识地下载并打开电子邮件。电子邮件中包含的可执行文件旨在执行用于内部侦测的端口扫描，并在目标主机和攻击者之间建立静默连接。&lt;/p&gt;
&lt;p&gt;图 1 显示了我们的动机示例的出处图。图中的节点表示系统实体，箭头表示实体之间的定向交互。显示的图是通过删除大多数与攻击无关的实体和交互，从完整的来源图中抽象出来的子图。不同的节点形状对应不同类型的实体。被条纹覆盖的实体被视为恶意实体。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709698742850.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709698742850&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;prior-research-and-their-limitations&#34;&gt;Prior Research and their Limitations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;监督方法&lt;/strong&gt;：对于早期作品，需要&lt;strong&gt;构建特殊的启发式规则&lt;/strong&gt;来涵盖所有攻击模式。许多基于深度学习的APT检测方法基于良性和攻击性数据构建来源图，并以分类方式检测APT。这些监督方法可以在学习的攻击模式上获得近乎完美的检测结果，但在&lt;strong&gt;面临概念漂移或看不见的攻击模式时尤其容易受到攻击&lt;/strong&gt;。此外，对于基于规则的方法，启发式&lt;strong&gt;规则的构建和维护可能非常昂贵和耗时&lt;/strong&gt;。对于基于深度学习的方法，包含攻击的数据的稀缺性阻碍了这些监督方法的实际部署。针对上述问题，MAGIC 采用完全自监督的异常检测方式，在有效处理不可见攻击模式的同时，允许不存在包含攻击的数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于统计的方法&lt;/strong&gt;：最新的基于统计学的方法通过识别系统实体、交互和社区的稀有性或异常分数来检测APT信号。然而，系统实&lt;strong&gt;体的稀有性并不一定表明它们的异常&lt;/strong&gt;，通过因果分析或标签传播获得的异常评分是来源图上的浅层特征提取。为了说明这一点，在我们的攻击示例中，进程 tcexec 对不同的 IP 地址执行多个端口扫描操作（参见图 1），这可以被视为正常的系统行为。但是，考虑到源自外部网络的进程 tcexec 也会读取敏感的系统信息 （uname） 并与公共 IP 地址 （162.66.239.75） 建立连接，我们可以很容易地将 tcexec 识别为恶意实体。由于无法提取系统实体之间的深层语义和相关性，通常会导致基于统计的方法检测性能低下和误报率高。然而，MAGIC采用图表示模块对来源图进行深度图特征提取，从而产生高质量的嵌入。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;基于 DL 的方法&lt;/strong&gt;：最近，基于DL的APT检测方法，无论是有监督还是无监督，都产生了非常有希望的检测结果。然而，在现实中，中型企业每天会产生数百GB的审计日志。因此，基于深度学习的方法，特别是基于序列的和基于图形的方法，由于其&lt;strong&gt;计算开销&lt;/strong&gt;而不可行。例如，ATLAS平均需要 1 小时才能在 676MB 的审计日志上进行训练，而 ShadeWatcher在具有 GPU 的 DARPA E3 Trace 数据集上训练平均需要 1 天。此外，一些基于图自编码器的方法在来源图规模扩大时会遇到爆炸性内存开销问题。MAGIC 通过&lt;strong&gt;引入图形掩码自动编码器避免了计算要求高&lt;/strong&gt;，并在短短几分钟内完成了对 DARPA E3 Trace 数据集的训练。第 6.4 节中详细介绍了 MAGIC 的性能开销。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;端到端方法&lt;/strong&gt;：除了上面讨论的三个主要局限性之外，还值得一提的是，最新的APT检测方法是端到端检测器，并且专注于一个特定的检测任务。例如，ATLAS专注于端到端的攻击重建，而 Unicorn则从流日志中生成系统级警报。相反，MAGIC的方法是通用的，可以在各种检测场景下执行多粒度APT检测，也可以应用于从不同来源收集的审计日志。&lt;strong&gt;（什么叫通用的？预训练精调？还是知识说能检测多场景多力度就算通用了？）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;threat-model-and-definitions&#34;&gt;Threat Model and Definitions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;威胁模型&lt;/strong&gt;：我们假设攻击者来自系统外部，并以系统内的有价值信息为目标。攻击者可能会执行复杂的步骤来实现其目标，但在日志中留下可追踪的证据。系统硬件、操作系统和系统审计软件的组合是我们值得信赖的计算基础。在我们的威胁模型中不考虑毒物攻击和逃避攻击。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;出处图&lt;/strong&gt;：来源图是从原始审计日志中提取的有向循环图。构建来源图是数据来源的常见做法，因为它连接系统实体并呈现它们之间的交互关系。来源图包含代表不同系统实体（例如，进程、文件和套接字）的节点，以及代表系统实体之间交互（例如，执行和连接）的边缘，并标有它们的类型。例如，/tmp/tcexec 是一个 FileObject 系统实体，而 /tmp/tcexec 和 tcexec 之间的边缘是 FileObject 面向 Process 的执行操作（参见图 1）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多粒度检测&lt;/strong&gt;：MAGIC 能够执行&lt;strong&gt;两个粒度&lt;/strong&gt;的 APT 检测：批处理日志级别和系统实体级别。MAGIC的多粒度检测能力催生了两阶段检测方法：首先对流式日志进行批量日志级检测，然后对正批次进行系统实体级检测，以识别详细的检测结果。将这种方法应用于实际环境将有效减少工作量、资源消耗和误报，同时产生详细的结果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;批处理日志级别检测。在这种粒度的 APT 检测下，主要任务是给定来自一致来源的批量审核日志，如果在一批日志中检测到潜在的 APT，MAGIC 会发出警报。与Unicorn类似，MAGIC无法在这种检测粒度下准确定位恶意系统实体和交互。&lt;/li&gt;
&lt;li&gt;系统实体级检测。在这种粒度的APT检测下，检测任务是给定来自一致来源的审计日志，MAGIC能够在这些审计日志中准确定位恶意系统实体。在APT期间识别关键系统实体对于后续任务（如攻击调查和攻击故事恢复）至关重要，因为它提供了可解释的检测结果，并减少了对领域专家的需求以及冗余的手动工作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MAGIC是一种新型的自监督APT检测方法，它利用掩蔽图表示学习和异常值检测方法，能够对海量审计日志进行高效的多粒度检测。MAGIC的流水线由三个主要组件组成：（1）来源图构建，（2）图表示模块和（3）检测模块。它还提供了可选的 （4） 模型适配机制。在训练过程中，MAGIC 用 （1） 转换训练数据，用 （2） 学习图嵌入，用 （3） 记住良性行为。在推理过程中，MAGIC 使用 （1） 转换目标数据，使用训练的 （2） 获得图形嵌入，并通过 （3） 检测异常值。图 2 概述了 MAGIC 架构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709702251187.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709702251187&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;系统审计软件收集的流式审计日志通常以批量方式存储。在来源图构建 （1） 期间，MAGIC 将这些日志转换为静态来源图。系统实体及其之间的交互被提取并分别转换为节点和边。使用几种降低复杂性的技术来删除冗余信息。 	然后，将构建的出处图通过图表示模块（2）馈送，以获得输出嵌入（即对象的综合向量表示）。图表示模块基于图屏蔽自动编码器构建，并集成了基于样本的结构重构，将节点和边属性嵌入、传播和聚合到输出嵌入中，这些嵌入包含节点嵌入和系统状态嵌入。图形表示模块仅使用良性审核日志进行训练，以对良性系统行为进行建模。在对可能包含攻击的审计日志执行 APT 检测时，MAGIC 利用基于输出嵌入的异常值检测方法来检测系统行为中的异常值 （3）。根据任务的粒度，使用不同的嵌入来完成 APT 检测。在批处理日志级任务中，反映整个系统一般行为的系统状态嵌入是检测目标。此类嵌入中的异常值意味着其相应的系统状态是看不见的，并且可能是恶意的，这会显示该批次中的 APT 信号。在系统实体级任务中，检测目标是那些节点嵌入，它们表示系统实体的行为。节点嵌入中的异常值表示可疑的系统实体，并以更精细的粒度检测 APT 威胁。&lt;/p&gt;
&lt;p&gt;在实际检测设置中，MAGIC 有两个预先设计的应用程序。对于系统审计软件收集的每批日志，可以直接利用MAGIC的实体级检测来准确识别批次中的恶意实体，也可以按照第2.3节的规定进行两阶段检测。在这种情况下，MAGIC 首先扫描批次并查看批次中是否存在恶意信号（批处理日志级别检测）。如果警报为阳性，则 MAGIC 将执行实体级检测，以更精细的粒度识别恶意系统实体。与实体级检测相比，批量日志级别检测的计算要求要低得多。因此，这样的两阶段例程可以帮助MAGIC的用户节省计算资源，避免误报，同时不影响MAGIC的检测细度。但是，如果用户喜欢对所有系统实体进行细粒度检测，则前一个例程仍然是一个可访问的选项。&lt;/p&gt;
&lt;p&gt;为了应对概念漂移和看不见的攻击（unseen attack），采用了可选的模型适配机制为其用户提供反馈渠道（4）。由安全分析师检查和确认的检测结果将反馈给 MAGIC，帮助其以半监督的方式适应良性系统行为变化。在这种情况下，MAGIC获得了更有希望的检测结果，这将在第6.3节中讨论。此外，MAGIC 可以很容易地应用于现实世界的在线 APT 检测，这要归功于它能够适应概念漂移和最小的计算开销。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1用的啥？2用的基于图屏蔽自动编码器，3用的啥？KNN? &lt;del&gt;（4）是干啥的？&lt;/del&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（4）是靠人工标注进行监督学习的。&lt;/p&gt;
&lt;h3 id=&#34;unseen-attack&#34;&gt;unseen attack&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;Unseen attack&amp;rdquo;（不可见攻击）是一种高级持续性威胁（Advanced Persistent Threat，APT）攻击中的一种策略。这种攻击手段的目标是使攻击者的活动对受害者尽可能地不可见，让受害者很难察觉到自己受到了攻击。&lt;/p&gt;
&lt;p&gt;这种类型的攻击通常采取了多种隐蔽的方法，旨在规避传统安全监控和检测工具的检测。一些常见的不可见攻击技术包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;无文件攻击（Fileless Attacks）&lt;/strong&gt;：这种攻击方式不会在受害者系统上留下可被传统防病毒软件等检测到的文件。攻击者通过利用系统内置的工具或脚本语言，例如 PowerShell 或 WMI (Windows Management Instrumentation)，在内存中执行恶意代码。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐蔽通信&lt;/strong&gt;：攻击者会使用加密或隐藏的通信渠道，以避免被网络监控和入侵检测系统检测到。这可能包括使用加密协议、隐蔽通信端口或者隐藏在合法网络流量中的恶意数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低频攻击&lt;/strong&gt;：攻击者会在较长时间间隔内执行活动，以减少被检测到的风险。这种攻击方式通常不会引起系统管理员的注意，因为攻击活动没有频繁发生。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持续访问&lt;/strong&gt;：攻击者在成功进入受害者网络后，会尽可能长时间地保持对系统的访问，以获取更多的信息和权限。他们可能会隐藏在系统的深层次，并悄悄地窃取数据或监视受害者的活动。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态改变攻击模式&lt;/strong&gt;：攻击者会不断地改变他们的攻击方式和工具，以规避传统的安全防御措施。这种变化性可以使传统的签名检测和规则检测方法失效。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;design-details&#34;&gt;Design Details&lt;/h2&gt;
&lt;h3 id=&#34;provenance-graph-construction&#34;&gt;Provenance Graph Construction&lt;/h3&gt;
&lt;p&gt;MAGIC 首先从原始审计日志中构建出处图，然后再执行图表示和 APT 检测。我们遵循三个步骤来构建一致且优化的来源图，为图表示做好准备。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;日志解析&lt;/strong&gt;：第一步是简单地解析每个日志条目，提取系统实体以及它们之间的系统交互。然后，可以构建一个原型出处图，以系统实体为节点，以交互为边。现在，我们提取有关节点和边的分类信息。对于提供实体和交互标签的简单日志格式，我们直接使用这些标签。对于提供这些实体和交互的复杂属性的某种格式，我们应用多标签哈希（例如，xxhash）将属性转换为&lt;strong&gt;标签&lt;/strong&gt;。在这个阶段，来源图是有向多图。我们设计了一个示例来演示如何处理图 3 中日志解析后的原始来源图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;初始嵌入&lt;/strong&gt;：在这个阶段，我们将节点和边标签转换为维度 d 的固定大小的特征向量（即初始嵌入），其中 d 是图表示模块的隐藏维度。我们应用了查找嵌入，在节点/边标签和 d 维特征向量之间建立了一对一的映射。如图 3（I 和 II）所示，进程 a 和 b 共享相同的标签，因此它们映射到相同的特征向量，而 a 和 c 嵌入到不同的特征向量中，因为它们具有不同的标签。我们注意到，唯一节点/边缘标签的可能数量由数据源（即审计日志格式）决定。因此，查找嵌入在转导设置下工作，不需要学习看不见的标签的嵌入。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709705666067.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709705666067&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;降噪&lt;/strong&gt;：我们的图表示模块的预期输入出处图将是简单图。因此，我们需要在节点对之间组合多个边。如果一对节点之间存在同一标签的多个边（也共享相同的初始嵌入），我们将删除多余的边，以便只保留其中一条。然后，我们将剩余的边合并为一条最终边。我们注意到，在一对节点之间，可能会保留几个不同标签的边缘。组合后，通过对剩余边的初始嵌入进行平均来获得所得唯一边的初始嵌入。为了说明这一点，我们在图3（II和III）中展示了我们的降噪如何结合多边，以及它如何影响边的初始嵌入。首先，对于每个标签，将 a 和 c 之间的 3 次读取和 2 次写入交互合并为一个。然后我们将它们组合在一起，形成一个边缘 eac，其初始嵌入等于其余边缘的&lt;strong&gt;平均&lt;/strong&gt;初始嵌入（e′ 2 和 e′ 5）。我们在附录E中提供了我们的降噪步骤与以前工作的比较&lt;/p&gt;
&lt;p&gt;简单来说就是先对边和节点进行多标签哈希，目的是将多个类别标签映射到设计的那几个标签上（如果是有标签的日志格式则不需要这一步），这样每个边都有标签，标签就是边的含义（read,write等)。然后将节点和标签转为d维的初始嵌入，再将节点对之间嵌入值相同的边合并成一个边。&lt;/p&gt;
&lt;h3 id=&#34;graph-representation-module&#34;&gt;Graph Representation Module&lt;/h3&gt;
&lt;p&gt;MAGIC 采用图表示模块从特色出处图（featured provenance graphs）中获取高质量的嵌入。如图 4 所示，图表示模块由三个阶段组成：用于部分隐藏节点特征（即初始嵌入）以进行重建的掩码过程，通过传播和聚合图特征生成节点和系统状态输出嵌入的图编码器，图解码器通过掩码特征重建和基于样本的结构为图表示模块的训练提供监督信号重建。编码器和解码器形成图形掩码自动编码器，在生成快速且节省资源的嵌入方面表现出色。&lt;/p&gt;
&lt;h4 id=&#34;feature-masking&#34;&gt;Feature Masking&lt;/h4&gt;
&lt;p&gt;在训练我们的图表示模块之前，我们对节点执行掩码，以便在重建这些节点时可以训练图掩码自动编码器。屏蔽节点是随机选择的，覆盖所有节点的一定比例。此类屏蔽节点的初始嵌入将替换为特殊的屏蔽令牌 xmask，以涵盖有关这些节点的任何原始信息。但是，边缘不会被屏蔽，因为这些边缘提供了有关系统实体之间关系的宝贵信息。总之，给定节点初始嵌入 $x_n$，我们按如下方式屏蔽节点：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709708984909.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709708984909&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中 $\tilde{N}$ 是随机选择的掩码节点，$emb_n$ 是节点 n 的嵌入，准备训练图表示模块。此掩蔽过程仅在训练期间发生。在检测过程中，我们不会屏蔽任何节点。&lt;/p&gt;
&lt;h4 id=&#34;graph-encoder&#34;&gt;Graph Encoder&lt;/h4&gt;
&lt;p&gt;从图构建步骤中获得的初始嵌入仅考虑原始特征。然而，原始特征还远远不足以对系统实体的详细行为进行建模。实体的上下文信息，如其邻域、多跳关系以及与其他系统实体的交互模式，对于获得高质量的实体嵌入起着重要作用。在这里，我们采用并扩展了&lt;strong&gt;图形屏蔽自编码器&lt;/strong&gt;，以自监督的方式生成输出嵌入。图形屏蔽自动编码器由编码器和解码器组成。编码器通过传播和聚合图特征来生成输出嵌入，解码器重建图特征以提供用于训练的监督信号。这种编码器-解码器架构在生成的嵌入中保留了上下文和语义信息，同时通过掩蔽学习显着降低了其计算开销。&lt;/p&gt;
&lt;p&gt;我们的图表示模块的编码器包含多个堆叠层的图注意力网络（GAT）。GAT层的功能是根据节点本身及其相邻节点的特征（初始嵌入）生成输出节点嵌入。与普通的GNN不同，GAT引入了一种注意力机制来衡量这些邻居的重要性。【GAT加了attention真的还好算吗？训练代价应该也不小吧】&lt;/p&gt;
&lt;p&gt;为了详细解释，GAT 的一层将前几层生成的节点嵌入作为输入，并将嵌入从源节点传播到目标节点，并沿交互传播到消息中。该消息包含有关源节点以及源节点和目标节点之间交互的信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709710234712.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709710234712&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;并采用注意力机制来计算消息源与其目的地之间的注意力系数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709710298170.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709710298170&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;然后，对于目标节点，GAT 聚合来自传入边缘的消息，以通过计算所有传入消息的加权和来更新其节点嵌入。权重正是注意力系数：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709710344097.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709710344097&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中 $h^l_n$ 是 GAT 第 l 层节点 n 的隐藏嵌入，$h^{l-1}_n$ 是 l − 1 层的隐藏嵌入，$\mathcal{N}&lt;em&gt;n$ 是 n 的单跳邻域。第一个 GAT 层的输入是初始节点嵌入。Embe 是初始边缘嵌入，在整个图形表示模块中保持不变。$W_as$，$W_am$，$W&lt;/em&gt;{self}$ ，$W{msg}$ 是可训练的参数。更新的节点嵌入构成了节点单跳交互行为的一般抽象。&lt;/p&gt;
&lt;p&gt;将此类 GAT 的多层堆叠以获得最终的节点嵌入 h，该节点嵌入由原始节点嵌入和所有 GAT 层的输出连接起来：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709710765514.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709710765514&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中 ·||·表示串联操作。GAT堆叠的层数越多，相邻范围就越宽，节点的多跳交互模式能够表示的就越远。因此，图编码器有效地结合了节点初始特征和多跳交互行为，将系统实体行为抽象到节点嵌入中。图编码器还对所有节点嵌入应用平均池化，以生成图本身的全面嵌入，它概括了系统的整体状态：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709710804533.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709710804533&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;图编码器生成的节点嵌入和系统状态嵌入被视为图表示模块的输出，用于不同场景下的后续任务。&lt;/p&gt;
&lt;h4 id=&#34;graph-decoder&#34;&gt;Graph Decoder&lt;/h4&gt;
&lt;p&gt;图形编码器不提供支持模型训练的监督信号。在典型的图自编码器中，使用图解码器对节点嵌入进行解码，并通过特征重构和结构重构来监督模型训练。然而，图形屏蔽自编码器放弃了结构重建，以减少计算开销。我们的图解码器是两者的混合体，它集成了掩码特征重建和基于样本的结构重建，以构建优化图表示模块的目标函数。&lt;/p&gt;
&lt;p&gt;给定从图编码器获得的节点嵌入 $h_n$，解码器首先重新屏蔽这些屏蔽节点，并将它们转换为屏蔽特征重建的输入：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709711180082.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709711180082&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;随后，解码器使用上述类似的GAT层来重建掩码节点的初始嵌入，从而可以计算特征重建损失：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709711206698.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709711206698&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;【所以这个掩码节点是拿个seed全局保留的马？】&lt;/p&gt;
&lt;p&gt;其中 $L_{fr} $是通过计算掩码节点的初始嵌入和重建嵌入之间的缩放余弦损失获得的掩蔽特征重建损失。这种损失在简单样本和困难样本之间急剧增加，从而有效地加快了学习速度。这种缩放的程度由超参数γ控制。&lt;/p&gt;
&lt;p&gt;与此同时，基于样本的结构重建旨在重建图结构（即预测节点之间的边）。与重建整个邻接矩阵不同，后者具有O(N2)的复杂度，基于样本的结构重建在节点对上应用对比采样，并预测这些节点对之间的边概率。仅非掩蔽节点参与结构重建。正样本是由所有非掩蔽节点之间的所有现有边构建的，负样本则是在那些没有现有边的节点对中进行采样构建的。&lt;/p&gt;
&lt;p&gt;使用简单的两层 MLP 重建节点对样本之间的边，为每个样本生成一个概率。在这些样本上，重建损失的形式为简单的二元交叉熵损失：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709711513256.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709711513256&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中 （n， n−） 和 （n， n+） 分别是负样本和正样本，ˆ N =N− e N 是一组非掩码节点。基于样本的结构重建仅对输出嵌入进行监督。我们没有使用点积，而是使用 MLP 来计算边缘概率，因为交互实体的行为不一定相似。此外，我们并没有强迫模型学习预测边缘概率。这种结构重构的功能是最大化抽象节点嵌入中包含的行为信息，以便一个简单的MLP足以将这些信息合并并解释为边缘概率。&lt;/p&gt;
&lt;p&gt;最终的目标函数 L = $L_fr$ + $L_sr$ 结合了 $L_fr$ 和 $L_sr$，并为图表示模块提供监督信号，使其能够以自监督的方式学习参数。&lt;/p&gt;
&lt;h3 id=&#34;detection-module&#34;&gt;Detection Module&lt;/h3&gt;
&lt;p&gt;基于图表示模块生成的输出嵌入，利用异常值检测方法以无监督方式进行APT检测。如前几节所述，此类嵌入以不同的粒度总结了系统行为。我们的检测模型的目标是识别恶意系统实体或状态，前提是仅对良性系统行为有先验的了解。如果通过图表示学习生成的嵌入在图中具有相似的交互行为，则它们的相应实体往往会形成聚类。因此，系统状态嵌入中的异常值表示不常见和可疑的系统行为。基于这样的洞见，我们开发了一种特殊的异常值检测方法来进行APT检测。&lt;/p&gt;
&lt;p&gt;在训练过程中，首先从训练来源图中抽象出良性输出嵌入。在这个阶段，检测模块所做的只是记住这些嵌入，并将它们组织在一个K-D树中[33]。经过训练后，检测模块通过三个步骤揭示异常值：k-最近邻搜索、相似度计算和过滤。给定目标嵌入，检测模块首先通过 K-D 树搜索获得其 k 最近邻。这样的搜索过程只需要 log（N） 时间，其中 N 是记忆训练嵌入的总数。然后，应用相似性准则来评估目标嵌入与其邻居的接近程度并计算异常分数。如果其异常分数高于超参数 θ，则目标嵌入被视为异常值，其相应的系统实体或系统状态为恶意。检测模块的示例工作流程形式化如下，使用欧几里得距离作为相似性准则：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709711997347.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709711997347&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中 $\overline{dist}$ 是训练嵌入与其 k 最近邻之间的平均距离。在执行批处理日志级别检测时，检测模块会记住反映系统状态的良性系统状态嵌入，并检测新到达的来源图的系统状态嵌入是否为异常值。在执行系统实体级检测时，检测模块会记住指示系统实体行为的良性节点嵌入，并给定一个新到达的来源图，它会检测所有系统实体嵌入中的异常值。&lt;/p&gt;
&lt;h3 id=&#34;model-adaption&#34;&gt;Model Adaption&lt;/h3&gt;
&lt;p&gt;为了使APT检测器在实际检测场景中有效运行，必须考虑概念漂移。当面对良性但以前未见过的系统行为时，MAGIC 会产生误报检测结果，这可能会误导后续应用程序（例如攻击调查和故事恢复）。最近的工作通过忘记过时的数据[10]或通过模型适应机制[18]将他们的模型拟合到良性系统变化来解决这个问题。MAGIC还集成了模型适应机制，以对抗概念漂移，并从安全分析师识别的误报中学习。与其他仅使用误报来重新训练模型的作品略有不同，MAGIC可以使用所有反馈进行重新训练。如前几节所述，MAGIC 中的图形表示模块以自监督的方式将系统实体编码为嵌入，而无需知道其标签。任何看不见的数据，包括那些true negative，都是图表示模块的宝贵训练数据，以增强其对看不见的系统行为的表示能力。&lt;/p&gt;
&lt;p&gt;检测模块只能通过良性反馈进行重新训练，以跟上系统行为的变化。而且随着它记住越来越多的良性反馈，它的检测效率会降低。为了解决这个问题，我们还在检测模块上实现了折扣机制。当记忆嵌入的数量超过一定数量时，随着新到达的嵌入被学习，最早的嵌入被简单地删除。我们提供模型适配机制作为概念漂移和看不见的系统行为的可选解决方案。建议通过将确认的假阳性样本提供给 MAGIC 的模型适应机制来使 MAGIC 适应系统变化。&lt;/p&gt;
&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;我们在 Python 3.8 中使用了大约 3,500 行代码实现了 MAGIC。我们开发了几个日志解析器来应对不同格式的审计日志，包括 StreamSpot [34]、Camflow [35] 和 CDM [36]。来源图是使用图处理库 Networkx [37] 构建的，并以 JSON 格式存储。图形表示模块是通过 PyTorch [38] 和 DGL [39] 实现的。该检测模块是用Scikit-learn[40]开发的。对于MAGIC的超参数，特征重建损失中的比例因子γ设置为3，相邻变量k设置为10，学习率为0.001，权重衰减因子等于5×10−4。我们在实验中使用了 3 层图形编码器和 0.5 的掩码率。在批处理日志级别检测和实体级检测两种检测方案中，输出嵌入维度 d 是不同的。我们在批处理日志级别检测中使用 d 等于 256，在实体级检测中使用 和 an 等于 64 以减少资源消耗。检测阈值 θ 是通过对每个数据集分别进行的简单线性搜索来选择的。超参数可能有其他选择。我们将在稍后的评估部分演示这些超参数对 MAGIC 的影响。在我们的超参数分析中，d 是从 {16， 32， 64， 128， 256} 中选出的，l 是从 {1， 2， 3， 4} 中选出的，r 是从 {0.3， 0.5， 0.7} 中选出的。对于阈值 θ，在批处理日志级别检测中选择介于 1 和 10 之间。有关实体级检测，请参阅附录 D。&lt;/p&gt;
&lt;h2 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;我们使用来自各种系统审计软件的 131GB 审计日志来评估 MAGIC 的有效性和效率。我们首先描述了我们的实验设置（第 6.1 节），然后详细说明了 MAGIC 在不同场景中的有效性（第 6.2 节），进行误报分析并评估模型适应机制的有用性（第 6.3 节），并分析了 MAGIC 的运行时性能开销（第 6.4 节）。MAGIC的不同组件和超参数的影响在第6.5节中进行了分析。此外，附录 C 中还对我们的动机示例进行了详细的案例研究，以说明 MAGIC 的管道如何用于 APT 检测。这些实验在相同的设备设置下进行。&lt;/p&gt;
&lt;h3 id=&#34;experimental-settings&#34;&gt;Experimental Settings&lt;/h3&gt;
&lt;p&gt;我们评估了MAGIC在三个公共数据集上的有效性：StreamSpot数据集[21]，Unicorn Wget数据集[22]和DARPA Engagement 3数据集[20]。这些数据集在数量、来源和粒度方面各不相同。我们相信，通过在这些数据集上测试MAGIC的性能，我们能够将MAGIC与尽可能多的最先进的APT检测方法进行比较，并探索MAGIC的普遍性和适用性。我们对这三个数据集的详细说明如下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;StreamSpot 数据集&lt;/strong&gt;：StreamSpot数据集（见表1）是由StreamSpot[34]使用审计系统SystemTap [41]收集并公开的模拟数据集。StreamSpot 数据集包含 600 批次审计日志，用于监控 6 个独特场景下的系统调用。其中五个方案是模拟的良性用户行为，而攻击方案模拟的是偷渡式下载攻击。该数据集被认为是一个相对较小的数据集，由于没有提供日志条目和系统实体的标签，因此我们对 StreamSpot 数据集执行批量日志级别检测，类似于以前的工作 [10， 15， 17]。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unicorn Wget 数据集&lt;/strong&gt;：Unicorn Wget数据集（见表1）包含Unicorn[10]设计的模拟攻击。具体来说，它包含 Camflow [35] 收集的 150 批日志，其中 125 批是良性的，其中 25 批包含供应链攻击。这些攻击被归类为隐形攻击，经过精心设计，其行为类似于良性系统工作流程，预计很难识别。这个数据集被认为是我们实验数据集中最难的，因为它的体积大，日志格式复杂，而且这些攻击的隐蔽性。与最先进的方法相同，我们在此数据集上执行批处理日志级别检测。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709712995732.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709712995732&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DARPA E3 数据集&lt;/strong&gt;：DARPA Engagement 3 数据集（见表 2）作为 DARPA 透明计算计划的一部分，在对抗性参与期间在企业网络中收集。利用不同漏洞的 APT 攻击 [20] 由红队进行，以泄露敏感信息。蓝队试图通过审核网络主机并对其执行因果关系分析来识别这些攻击。Trace、THEIA 和 CADETS 子数据集包含在我们的评估中。这三个子数据集总共包含 51.69GB 的审计记录，包含多达 6,539,677 个系统实体和 68,127,444 次交互。因此，我们评估了MAGIC的系统实体级检测能力，并解决了这些数据集的开销问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713015449.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713015449&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对于不同的数据集，我们采用不同的数据集拆分来评估模型，并且我们仅使用良性样本进行训练。对于 StreamSpot 数据集，我们从 500 个良性日志中随机选择 400 个批次进行训练，其余批次进行测试，从而形成一个平衡的测试集。对于 Unicorn Wget 数据集，选择了 100 批良性日志进行训练，其余用于测试。对于 DARPA E3 数据集，我们使用与 ThreaTrace [17] 相同的真值标签，并根据其出现的顺序拆分日志条目。最早的 80% 日志条目用于训练，其余条目保留用于测试。在评估过程中，MAGIC在100个全局随机种子下的平均性能被报告为最终结果，因此实验结果可能包含系统实体/日志批次的分数。&lt;/p&gt;
&lt;h3 id=&#34;effectiveness&#34;&gt;Effectiveness&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713083774.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713083774&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713103510.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713103510&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713117689.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713117689&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713129950.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713129950&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713153070.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713153070&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713173936.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713173936&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713196429.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713196429&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1709713209284.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1709713209284&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;conclusion&lt;/h2&gt;
&lt;p&gt;我们推出了 MAGIC，这是一种普遍适用的 APT 检测方法，它以最高的效率运行，开销很小。MAGIC 利用掩码图表示学习从原始审计日志中对良性系统行为进行建模，并通过异常值检测方法执行多粒度 APT 检测。在各种检测场景下对三个广泛使用的数据集进行评估表明，MAGIC以低误报率和最小的计算开销取得了良好的检测结果。&lt;/p&gt;
&lt;h2 id=&#34;知识补充&#34;&gt;知识补充&lt;/h2&gt;
&lt;h3 id=&#34;多标签哈希&#34;&gt;多标签哈希&lt;/h3&gt;
&lt;p&gt;多标签哈希（Multi-Label Hashing）是一种用于解决多标签分类问题的技术。在多标签分类问题中，每个样本可以属于一个或多个类别，而不是单一的类别。&lt;/p&gt;
&lt;p&gt;哈希是一种将数据映射到固定长度的二进制编码的方法。多标签哈希技术将这种哈希方法应用于多标签分类问题，将样本的多个标签映射为固定长度的二进制编码，从而方便快速的类别检索和处理。&lt;/p&gt;
&lt;p&gt;以下是多标签哈希的一些关键思想和方法：&lt;/p&gt;
&lt;h4 id=&#34;1-单一哈希方法&#34;&gt;1. 单一哈希方法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Bit-Vector Hashing&lt;/strong&gt;：最简单的多标签哈希方法之一是将每个标签映射为二进制编码的位向量。例如，如果有5个类别，则可以用5位二进制编码来表示每个标签，如 &lt;code&gt;[1, 0, 1, 1, 0]&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-多哈希方法&#34;&gt;2. 多哈希方法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Binary Relevance&lt;/strong&gt;：这种方法将每个标签独立地进行哈希处理。对于每个标签，都使用一个单独的哈希函数，将其映射为固定长度的二进制编码。这种方法简单直观，但可能导致标签之间的相关性被忽略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multiple Hashing&lt;/strong&gt;：这种方法使用多个哈希函数，将每个标签映射为多个不同的二进制编码。这可以捕捉到标签之间的一些相关性，提高多标签哈希的性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-哈希函数的选择&#34;&gt;3. 哈希函数的选择&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;局部敏感哈希（Locality Sensitive Hashing，LSH）&lt;/strong&gt;：LSH 是一种常用的哈希方法，它能够使相似的样本在哈希空间中映射为相邻的编码。这有助于快速的近似最近邻（ANN）搜索，对于多标签分类中的相似性检索很有用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep Learning Hashing&lt;/strong&gt;：使用深度学习模型学习哈希函数也是一种常见的方法。例如，可以使用卷积神经网络（CNN）或循环神经网络（RNN）来学习将标签映射为二进制编码的函数。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;4-检索和评估&#34;&gt;4. 检索和评估&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;哈希编码检索&lt;/strong&gt;：一旦对样本进行了哈希处理，可以使用快速的哈希编码检索技术来查找与查询标签最相似的样本。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;评估指标&lt;/strong&gt;：对于多标签哈希，常用的评估指标包括 Hamming Loss、Hamming Distance、Precision、Recall、F1 Score 等，用于衡量模型的分类准确性和性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;多标签哈希方法可以提高对于多标签数据的处理效率和准确性，尤其在大规模的多标签数据集中具有很好的应用前景。&lt;/p&gt;
&lt;h3 id=&#34;图形掩蔽自编码器&#34;&gt;图形掩蔽自编码器&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;Graph Masked Autoencoders&amp;rdquo; 是一种用于图形数据的自编码器模型，旨在学习图形数据的低维度表示。&lt;/p&gt;
&lt;p&gt;这个模型的主要思想是结合了自编码器（Autoencoder）的概念和图形数据的结构。自编码器是一种无监督学习算法，用于学习数据的紧凑表示，并在重建时最大程度地保留原始数据的信息。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Graph Masked Autoencoders&amp;rdquo; 在这个基础上加入了一种“掩蔽”机制，用于处理图形数据。这个“掩蔽”机制的目的是在训练过程中限制模型只能看到部分图形数据，从而强制模型学习到更加泛化的图形特征表示。&lt;/p&gt;
&lt;p&gt;具体来说，训练过程包含以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;掩蔽图形数据（Masking Graph Data）&lt;/strong&gt;：模型会随机地将一些节点或边从输入图中“掩蔽”（即隐藏），使得模型在训练时只能看到部分图形数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编码器（Encoder）&lt;/strong&gt;：掩蔽后的图形数据通过编码器部分进行编码，将其映射到一个低维度的特征表示空间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;解码器（Decoder）&lt;/strong&gt;：然后，模型尝试从这个低维度表示中重构原始的图形数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过这个过程，模型被迫学习到不同节点和边之间的潜在关系，以及如何在只看到部分数据时对图形数据进行有效的编码和解码。&lt;/p&gt;
&lt;p&gt;这种方法的优势在于它能够提高模型对图形数据的泛化能力。因为模型只能看到部分数据，它不会过度依赖于特定的节点或边，从而可以更好地处理未见过的图形数据。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Graph Masked Autoencoders&amp;rdquo; 的应用包括图形节点分类、图形重构、图形生成等任务。它是图神经网络（Graph Neural Networks）领域中的一种重要技术，用于学习和处理复杂的图形结构数据。&lt;/p&gt;
&lt;h3 id=&#34;概念漂移&#34;&gt;概念漂移&lt;/h3&gt;
&lt;p&gt;概念漂移是指机器学习模型在应用于新数据时性能下降的现象。这种现象通常发生在训练模型的数据分布与新数据的分布不同时。具体来说，概念漂移可能会导致模型在新数据上的预测准确性降低。&lt;/p&gt;
&lt;p&gt;概念漂移可以分为几种不同类型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;特征漂移（Feature Drift）&lt;/strong&gt;：特征漂移是指输入特征的分布在训练数据和测试数据中不同的情况。例如，训练数据中的特征范围可能与测试数据中的范围不同，这会导致模型无法准确地泛化到新数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;标签漂移（Label Drift）&lt;/strong&gt;：标签漂移是指目标变量的分布在训练数据和测试数据中不同的情况。换句话说，模型在训练数据中学到的标签分布可能与实际数据中的标签分布不同，从而影响模型的性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;概念漂移（Concept Drift）&lt;/strong&gt;：概念漂移是指预测变量和目标变量之间的关系在时间或数据分布上发生变化。这种情况下，模型在训练时学到的规律可能在应用到新数据时不再适用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;概念漂移是机器学习应用中一个重要的挑战，因为它可能导致模型的预测性能下降，需要采取一些方法来处理。一些应对概念漂移的方法包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;在线学习（Online Learning）&lt;/strong&gt;：使用新数据不断更新模型，使其能够适应新的数据分布。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;监督漂移检测（Supervised Drift Detection）&lt;/strong&gt;：监测模型在新数据上的表现，当性能下降时触发模型的重新训练。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;集成学习（Ensemble Learning）&lt;/strong&gt;：结合多个模型的预测结果，以减少概念漂移对整体性能的影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;领域适应（Domain Adaptation）&lt;/strong&gt;：通过调整模型或数据来使其适应新的数据分布。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;处理概念漂移是一个活跃的研究领域，因为许多现实世界的应用场景中数据分布经常发生变化。&lt;/p&gt;
&lt;h3 id=&#34;k-d-tree&#34;&gt;K-D tree&lt;/h3&gt;
&lt;p&gt;K-D 树（K-Dimensional Tree，K-Dimensional Binary Tree）是一种用于高效处理k维空间的数据结构，用于解决近似最近邻搜索（Approximate Nearest Neighbor Search）等问题。它是一种二叉树结构，用于对 k 维数据进行分割和组织，以便快速地搜索最近的邻居。&lt;/p&gt;
&lt;h1 id=&#34;我的想法&#34;&gt;我的想法&lt;/h1&gt;
&lt;p&gt;和之前看的ATLAS比较起来，通过mask和减小模型复杂度来实现降低开销，并且没有造成结果的损失。好像就没啥更吊的地方了吧？&lt;/p&gt;
&lt;p&gt;加了个监督学习的步骤&lt;/p&gt;
&lt;p&gt;嵌入阶段用了mask和图&lt;strong&gt;注意力&lt;/strong&gt;网络的技术手段，能获得质量更高，多跳敏感的嵌入。&lt;/p&gt;
&lt;p&gt;通过检测时候通过KD树找到K个临近的embedding，然后通过相似性计算， 设立一个阈值来判断是否具有恶意。再用decoder来还原出embedding所对应的边或者节点&lt;/p&gt;
</description>
        </item>
        <item>
        <title>TFE GNN</title>
        <link>https://pillar23.github.io/p/tfe-gnn/</link>
        <pubDate>Fri, 16 Feb 2024 16:28:03 +0800</pubDate>
        
        <guid>https://pillar23.github.io/p/tfe-gnn/</guid>
        <description>&lt;h1 id=&#34;abstract&#34;&gt;abstract&lt;/h1&gt;
&lt;p&gt;目的：实现加密流量[VPN、tor]的分类&lt;/p&gt;
&lt;p&gt;现有局限性：只能提取低级别特征，基于统计的方法对&lt;strong&gt;短流&lt;/strong&gt;无效，对header和payload采取&lt;strong&gt;不平等&lt;/strong&gt;的处理，难以挖掘字节之间的潜在相关性。&lt;/p&gt;
&lt;p&gt;提出方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于逐点互信息(PMI)的字节级流量图构建方法&lt;/li&gt;
&lt;li&gt;基于图神经网络(TFE-GNN)进行特征提取的时序融合编码器模型&lt;/li&gt;
&lt;li&gt;引入了一个双嵌入层、一个基于GNN的流量图编码器以及一个交叉门控特征融合机制。[分别嵌入header和payload，然后通过融合实现数据增强]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;结果：两个真实数据集（WWT和ISCX）优于SOTA&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708314808397.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708314808397&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;introduction&lt;/h1&gt;
&lt;p&gt;加密流量保存用户隐私同时也给了攻击者藏身的机会。&lt;/p&gt;
&lt;p&gt;传统的数据包检测（DPI）挖掘数据包中的潜在模式或关键词，面对加密数据包时&lt;strong&gt;耗时&lt;/strong&gt;且准确性低。&lt;/p&gt;
&lt;p&gt;由于动态端口的应用，基于端口的工作不再有效。&lt;/p&gt;
&lt;p&gt;通过数据流的统计特征（e.g.数据包长度的平均值）采用机器学习分类器（e.g.随机森林）来实现分类的方法，需要手工制作的特征工程，并且在某些情况下可能会由于不可靠/不稳定的fow级统计信息而失败。与长流相比，短流的统计特征有更大的偏差（e.g.长度通常服从长尾分布）意味着不可靠的统计特征普遍存在。我们使用&lt;strong&gt;数据包字节&lt;/strong&gt;而非统计特征。&lt;/p&gt;
&lt;p&gt;GNN 可以识别图中隐含的特定拓扑模式，以便我们可以用预测标签对每个图进行分类。目前大多数GNN根据数据包之间的相关性来构建图，这实际上是统计特征的另一种使用形式，导致上述问题。&lt;/p&gt;
&lt;p&gt;用了数据包字节的方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;平等地对待header和payload，忽略了它们之间的含义差异。&lt;/li&gt;
&lt;li&gt;原始字节利用不足，只是将数据包视为节点，将原始字节作为节点特征，不能充分利用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文提出了一种基于逐点互信息（PMI）的字节级图构建方法，一种基于图神经网络(TFE-GNN)进行特征提取的时序融合编码器模型。通过挖掘字节之间的相关性来构建流量图，用作TFE-GNN的输入。&lt;/p&gt;
&lt;p&gt;TFE-GNN由三大子模块组成（即双嵌入、流量图编码器和交叉门控特征融合机制）。双嵌入层分别嵌入header和payload；图编码器将图编码为高维图向量；交叉门控特征融合机制对header和payload的图向量融合，得到数据包的整体表示向量。&lt;/p&gt;
&lt;p&gt;使用端到端训练（从输入数据到最终输出直接进行训练，而无需将任务分解为多个独立的阶段或模块），采用时间序列模型，获得下游任务的预测结果。&lt;/p&gt;
&lt;p&gt;实验使用了自收集的WWT（WhatsApp、WeChat、Telegram）和公开的ISCX数据集，与十几个baseline比较得出TFE-GNN效果最好。&lt;/p&gt;
&lt;h1 id=&#34;preliminary&#34;&gt;preliminary&lt;/h1&gt;
&lt;p&gt;1、图的定义&lt;/p&gt;
&lt;p&gt;G = { $V,\varepsilon,X$}表示一个图，V是节点集合，$\varepsilon$是边集，X是节点的初始特征矩阵（每个节点的特征向量拼起来）&lt;/p&gt;
&lt;p&gt;$A$是大小为$\lvert V \lvert * \lvert V \lvert$图的邻接矩阵&lt;/p&gt;
&lt;p&gt;$N(v)$是节点v相邻的节点&lt;/p&gt;
&lt;p&gt;$d_l$是第l层的嵌入维度&lt;/p&gt;
&lt;p&gt;TS(traffic segment)=[$P_{t_1},P_{t_2}&amp;hellip;P_{t_n}$]是一段时间内的数据包的集合。$P_{t_i}$是时间戳为$t_i$的数据包，n是流量序列的长度。$t_1,t_2$是流量序列的开始和结束时间。&lt;/p&gt;
&lt;p&gt;2、加密流量分类&lt;/p&gt;
&lt;p&gt;M是训练样本数量&lt;/p&gt;
&lt;p&gt;N是分类类别&lt;/p&gt;
&lt;p&gt;$bs^j_i=[b^{ij}_1, b^{ij}_2,&amp;hellip;,b^{ij}_m]$，m是字节序列长度，$b^{ij}_k$是第i个流量样本第j个字节序列的第k个字节&lt;/p&gt;
&lt;p&gt;$s_i=[bs^i_1,bs^i_2,&amp;hellip;,bs^i_n)]$，n是序列长度$bs^i_j$为第i个样本的第j个字节序列，可以理解为就是TS&lt;/p&gt;
&lt;p&gt;3、 MP-GNN&lt;/p&gt;
&lt;p&gt;MP-GNN 是 Message Passing Graph Neural Network（消息传递图神经网络）的简称，节点嵌入向量可以通过特定的聚合策略将节点的嵌入向量集成到邻域中，从而迭代更新节点嵌入向量。&lt;/p&gt;
&lt;p&gt;第l层 MP-GNN 可以形式化为两个过程&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708310294876.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708310294876&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中$h^{(l)}_u,h^{(l)}_v$是节点u和v在第l层的嵌入向量，$m^{(l)}_u$是l层中节点u的计算信息，$MSG^{(l)}$是消息计算函数，$AGG^{(l)}$是消息聚合函数，$\theta$是他们对应的参数&lt;/p&gt;
&lt;h1 id=&#34;methodology&#34;&gt;methodology&lt;/h1&gt;
&lt;h2 id=&#34;字节级流量图构造-byte-level-traffic-graph-construction&#34;&gt;字节级流量图构造 Byte-level Traffic Graph Construction&lt;/h2&gt;
&lt;p&gt;节点：某一个字节，注意相同的字节值共享同一个节点，因此节点个数不会超过256，这样能够保持图在一定的规模下，不会太大。&lt;/p&gt;
&lt;p&gt;字节之间的相关性表示：采用点互信息（PMI）来建模两个字节之间的相似性，字节i和字节j的相似性用$PMI(i,j)$表示。&lt;/p&gt;
&lt;p&gt;边：根据PMI值来构造边，PMI值为正：表示字节之间的语义相关性高；而PMI值为零或负值：表示字节之间的语义相关性很小或没有。因此，我们只在PMI值为正的两个字节之间创建一条边。&lt;/p&gt;
&lt;p&gt;节点特征：每个节点的初始特征为字节的值，维度为1，范围为[0,255]&lt;/p&gt;
&lt;p&gt;图构建：由于$PMI(i,j)=PMI(j,i)$，因此该图是个无向图。&lt;/p&gt;
&lt;h3 id=&#34;pmi&#34;&gt;PMI&lt;/h3&gt;
&lt;p&gt;PMI：是一种用于衡量两个事件之间相关性的统计量。&lt;/p&gt;
&lt;p&gt;$$
PMI(A, B) = \log \frac{P(A, B)}{P(A) \cdot P(B)}
$$&lt;/p&gt;
&lt;p&gt;值大于零，则表示 A 和 B 之间有正相关性；如果值等于零，则表示它们之间没有关联；如果值小于零，则表示它们之间有负相关性。&lt;/p&gt;
&lt;h2 id=&#34;双嵌入-dual-embedding&#34;&gt;双嵌入 dual embedding&lt;/h2&gt;
&lt;p&gt;原因：字节值通常用作进一步向量嵌入的初始特征。具有不同值的两个字节对应两个不同的嵌入向量。然而，字节的含义不仅随字节值本身而变化，还随它所在的字节序列的部分而变化。换句话说，在数据包的header和payload中，具有相同值的两个字节的表示含义可能完全不同。对于header和payload，使用&lt;strong&gt;两个不共享参数的嵌入层&lt;/strong&gt;的双嵌入，嵌入矩阵分别是$E_{header}$和$E_{payload}$&lt;/p&gt;
&lt;h2 id=&#34;交叉门控特征融合的流量图编码器-traffic-graph-encoder-with-cross-gated-feature-fusion&#34;&gt;交叉门控特征融合的流量图编码器 Traffic Graph Encoder with Cross-gated Feature Fusion&lt;/h2&gt;
&lt;p&gt;因为要double embedding，所以encoder也要两个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708314903093.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708314903093&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;这里堆叠了N个GraphSAGE&lt;/p&gt;
&lt;h3 id=&#34;graphsage&#34;&gt;GraphSAGE&lt;/h3&gt;
&lt;p&gt;对于图 G 中的每个节点 v，GraphSAGE 通过使用节点 v 的度数归一化其嵌入向量，计算来自每个相邻节点的消息。&lt;/p&gt;
&lt;p&gt;通过逐元素均值运算（element-wise mean operation）计算所有相邻节点$N(v)$的整体消息，并通过串联运算聚合整体消息以及节点v的嵌入向量&lt;/p&gt;
&lt;p&gt;对节点A的嵌入向量进行非线性变换，完成一个GraphSAGE层的正向过程&lt;/p&gt;
&lt;p&gt;GraphSAGE的消息聚合和计算可以描述为&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708315615539.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708315615539&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;$m^{(l)}_{N(v)}$是将v节点所有临接节点的上一层嵌入向量求平均的结果&lt;/p&gt;
&lt;p&gt;$h_v^{(l)}$是本层v节点的嵌入向量，$\sigma(\cdot)$是激活函数，$CONCAT(\cdot)$是连接函数。然后通过BatchNorm对h进行批量归一化&lt;/p&gt;
&lt;p&gt;激活函数选择PReLU，将每个负元素值按不同因子缩放，不但引入了非线性，还由于每个负元素的缩放因子的不同而起到类似于注意力机制的作用。&lt;/p&gt;
&lt;p&gt;由于深度GNN模型中的过度平滑问题，我们最多只堆叠GraphSAGE4层，并将输出拼接起来。这与跳转知识网络（JKL）相类似&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708316388852.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708316388852&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;最后，通过对每个节点的最终嵌入使用meanpooling来得到图嵌入&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708316889596.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708316889596&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;用$g_h,g_p$表示header和payload得到的图嵌入&lt;/p&gt;
&lt;h2 id=&#34;cross-gated-feature-fusion&#34;&gt;Cross-gated Feature Fusion&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708316997715.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708316997715&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;交叉门控特征融合，这个模块的目标是将$g_h,g_p$融合，获取门控矢量$s_h,s_p$。&lt;/p&gt;
&lt;p&gt;如上图，我们用了两个filter，每个filter的组成都是线性层、PReLU、线性层、Sigmoid。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708317405446.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708317405446&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中w和b分别是线性层的weight和bias。z 是数据包字节的整体表示向量。&lt;/p&gt;
&lt;h2 id=&#34;端到端的下游任务训练-end-to-end-training-on-downstream-tasks&#34;&gt;端到端的下游任务训练 End-to-End Training on Downstream Tasks&lt;/h2&gt;
&lt;p&gt;由于我们已经将流量段中每个数据包的原始字节编码为表示向量z，因此可以将段级分类任务视为时间序列预测任务。&lt;/p&gt;
&lt;p&gt;这里我们使用双层Bi-LSTM作为baseline，他的输出喂给一个带PReLU的两层线性分类器，使用交叉熵作为损失函数&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708318165707.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708318165707&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;n是长度，CE是交叉熵，y是ground truth（标注数据的分类标签）&lt;/p&gt;
&lt;p&gt;实验部分还有一个用transformer的&lt;/p&gt;
&lt;h1 id=&#34;experiments&#34;&gt;experiments&lt;/h1&gt;
&lt;p&gt;介绍了实验设置，在很多数据集和baseline上做了对比实验，&lt;strong&gt;做了消融实验（good）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;还分析了TFE-GNN的灵敏度，回答了&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个组件的功能&lt;/li&gt;
&lt;li&gt;哪个GNN架构效果最好&lt;/li&gt;
&lt;li&gt;TFE-GNN的复杂度如何&lt;/li&gt;
&lt;li&gt;超参数的变化在多大程度上会影响TFE-GNN的有效性&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;实验设置&#34;&gt;实验设置&lt;/h2&gt;
&lt;p&gt;数据集：ISCX VPN-nonVPN , ISCX Tor-nonTor , self-collected WWT datasets.&lt;/p&gt;
&lt;p&gt;预处理：对于每个数据集，筛除&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;空流或空段：所有数据包都没有有效负载（用于establish 连接）&lt;/li&gt;
&lt;li&gt;超长流或超长段：长度（即数据包数）大于 10000&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后对于每个数据包，删掉以太网标头，源 IP 地址和目标 IP 地址以及端口号都将被删除，以消除IP地址和端口号的敏感信息的干扰##&lt;/p&gt;
&lt;p&gt;细节：一个样本的最大数据包数设置为50，最大有效负载字节长度和最大标头字节长度分别设置为 150 和 40，PMI 窗口大小设置为 5&lt;/p&gt;
&lt;p&gt;epoch设置为120，lr为1e-2，用Adam优化器分512批次将lr从1e-2衰减到1e-4。warmup为0.1，droupout为0.2.\&lt;/p&gt;
&lt;p&gt;运行了10次实验。&lt;/p&gt;
&lt;p&gt;用AC、PR、RC和F1做评估&lt;/p&gt;
&lt;p&gt;和基于传统特征工程的方法（即 AppScanner [31]、CUMUL [23]、K-FP （K-Fingerprinting） [8]、FlowPrint [32]、GRAIN [43]、FAAR [19]、ETC-PS [40]）、基于深度学习的方法（即 FS-Net [18]、 EDC [16]、FFB [44]、MVML [4]、DF [30]、ET-BERT [17]）和基于图神经网络的方法（即 GraphDApp [29]、ECD-GNN [11]）做比较。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708319331300.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708319331300&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708319345719.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708319345719&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;消融实验&#34;&gt;消融实验&lt;/h2&gt;
&lt;p&gt;在 ISCX-VPN 和 ISCX-Tor 数据集上对 TFE-GNN 进行了消融实验，分别将头、有效载荷、双嵌入模块、跳跃知识网络式串联、交叉门控特征融合和激活函数以及批量归一化分别表示为 &amp;lsquo;H&amp;rsquo;、&amp;lsquo;P&amp;rsquo;、&amp;lsquo;DUAL&amp;rsquo;、&amp;lsquo;JKN&amp;rsquo;、&amp;lsquo;CGFF&amp;rsquo; 和 &amp;lsquo;A&amp;amp;N&amp;rsquo;。不仅验证了TFE-GNN中每个组件的有效性，而且还测试了一些替代模块或操作的影响，用sum、max替换mean，用GRU、transformer替换LSTM&lt;/p&gt;
&lt;p&gt;（只用H或P就不需要DUAL和CGFF）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708319828833.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708319828833&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;得出结论&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据包标头在分类中起着比数据包有效载荷更重要的作用，不同的数据集具有不同级别的标头和有效载荷重要性&lt;/li&gt;
&lt;li&gt;使用双嵌入使 f1 分数分别提高了 3.63% 和 0.95%，这表明其总体有效性。JKN样串联和交叉门控特征融合在两个数据集上都以相似的幅度增强了TFE-GNN的性能。&lt;/li&gt;
&lt;li&gt;缺少激活函数和批量归一化在两个数据集上都可以看到显著的性能下降，证明了其必要性&lt;/li&gt;
&lt;li&gt;用sum替换mean在两个数据集上分别差了11.1%和29.64%，用max替换mean在VPN上差很多在tor上只差一点&lt;/li&gt;
&lt;li&gt;用GRU替换LSTM导致两个都差10%左右，transformer替换LSTM导致VPN差了40%左右，tor上只差一点&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;换GNN架构为GAT, GIN, GCN and SGC，还是GraphSAGE最好&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708321015036.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708321015036&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;此外，通过TFE-GNN可以快捷的拓展一个segment级的全局特征&lt;/p&gt;
&lt;p&gt;复杂度&lt;/p&gt;
&lt;p&gt;TFE-GNN 在模型复杂度相对较小的情况下，在公共数据集上实现了最显着的改进。虽然ET-BERT在ISCX-nonVPN数据集上达到了可比的结果，但ET-BERT的FLOP大约是TFEGNN的五倍，模型参数的数量也增加了一倍，这通常表明模型推理时间更长，需要更多的计算资源。此外，ETBERT的预训练阶段非常耗时，由于预训练期间有大量的额外数据，并且模型复杂度高，因此成本很高。相比之下，TFE-GNN可以实现更高的精度，同时降低训练或推理成本。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708321171217.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708321171217&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;双重嵌入维度的影响。为了研究双嵌入层隐藏维度的影响，我们进行了灵敏度实验，结果如图a所示。正如我们所看到的，当嵌入维度低于 100 时，f1 分数会迅速增加。在此之后，随着维度的变化，模型性能趋于稳定。为了减少计算消耗，选取50作为默认维度&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1708321219227.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1708321219227&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;PMI窗口大小的影响。从图 b 中可以看出，较小的窗口大小通常会导致更好的 f1 分数。窗口越大图中添加的边就越多，由于图太密集，模型将更难分类。&lt;/p&gt;
&lt;p&gt;段长的影响。从图 c 中，我们可以得出一个结论，即用于训练的短段长度通常会使性能更好。&lt;/p&gt;
&lt;h1 id=&#34;conclusion-and-future-work&#34;&gt;conclusion and future work&lt;/h1&gt;
&lt;p&gt;我们提出了一种构建字节级流量图的方法和一个名为 TFE-GNN 的模型，用于加密流量分类。字节级流量图构造方法可以挖掘原始字节之间的潜在相关性并生成判别性流量图。TFE-GNN 旨在从构建的流量图中提取高维特征。最后，TFE-GNN可以将每个数据包编码为一个整体表示向量，该向量可用于一些下游任务，如流量分类。选择了几个基线来评估 TFE-GNN 的有效性。实验结果表明，所提模型全面超越了WWT和ISCX数据集上的所有基线。精心设计的实验进一步证明了TFE-GNN具有很强的有效性。&lt;/p&gt;
&lt;p&gt;将来，我们将尝试在以下限制方面改进 TFE-GNN。（1）有限的图构建方法。所提模型的图拓扑结构是在训练过程之前确定的，这可能会导致非最佳性能。此外，TFE-GNN无法应对每个数据包的原始字节中隐含的字节级噪声。（2） 字节序列中隐含的未使用的时间信息。字节级 trafc 图的构造没有引入字节序列的显式时间特征。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>复现Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow Interaction Graph Analysis</title>
        <link>https://pillar23.github.io/p/%E5%A4%8D%E7%8E%B0detecting-unknown-encrypted-malicious-traffic-in-real-time-via-flow-interaction-graph-analysis/</link>
        <pubDate>Wed, 25 Oct 2023 10:25:43 +0800</pubDate>
        
        <guid>https://pillar23.github.io/p/%E5%A4%8D%E7%8E%B0detecting-unknown-encrypted-malicious-traffic-in-real-time-via-flow-interaction-graph-analysis/</guid>
        <description>&lt;h1 id=&#34;导语&#34;&gt;导语&lt;/h1&gt;
&lt;p&gt;复现这篇2023NDSS论文，他大开源在https://github.com/fuchuanpu/HyperVision&lt;/p&gt;
&lt;h1 id=&#34;环境配置&#34;&gt;环境配置&lt;/h1&gt;
&lt;p&gt;我是在home下做的，如果想在别的地方搞稍微换下路径就行&lt;/p&gt;
&lt;p&gt;先拉git的代码 &lt;code&gt;git clone https://github.com/fuchuanpu/HyperVision.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;依照作者在readme里说，在纯净的ubuntu22.04上运行他的脚本即可。用docker装一个纯净的ubuntu22.04&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 下载镜像&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker pull homebrew/ubuntu22.04:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动，并且把~/HyperVision 和容器内的/root/HyperVision连起来&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -td --name hypervision -v &lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;/HyperVision&amp;#34;&lt;/span&gt;:/root/HyperVision homebrew/ubuntu22.04:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 进入&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; hypervision -it bash
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接下来的操作在docker里了&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo su
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; /root/HyperVision
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo ./env/install_all.sh &lt;span class=&#34;c1&#34;&gt;# 这里最好先换个国内的源，会把需要装的都装了&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://hypervision-publish.s3.cn-north-1.amazonaws.com.cn/hypervision-dataset.tar.gz &lt;span class=&#34;c1&#34;&gt;# 下载数据集，有6G，走的cdn，裸连速度就还不错&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -xzf hypervision-dataset.tar.gz &lt;span class=&#34;c1&#34;&gt;# 我也不知道为什么他写了个-xxf 如果想删掉原来的就删吧，不删也没关系&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./script/rebuild.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./script/expand.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; build &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ../script/run_all_brute.sh &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ..
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ./result_analyze
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./batch_analyzer.py -g brute
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat ./log/brute/*.log &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep AU_ROC
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1zj411e7xC/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.bilibili.com/video/BV1zj411e7xC/&lt;/a&gt;可以看到复现视频&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/fileName/1698203084469.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1698203084469&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Detecting Unknown Encrypted Malicious Traffic in Real Time via Flow Interaction Graph Analysis</title>
        <link>https://pillar23.github.io/p/detecting-unknown-encrypted-malicious-traffic-in-real-time-via-flow-interaction-graph-analysis/</link>
        <pubDate>Mon, 16 Oct 2023 20:34:22 +0800</pubDate>
        
        <guid>https://pillar23.github.io/p/detecting-unknown-encrypted-malicious-traffic-in-real-time-via-flow-interaction-graph-analysis/</guid>
        <description>&lt;h1 id=&#34;导语&#34;&gt;导语&lt;/h1&gt;
&lt;p&gt;doi is &lt;a class=&#34;link&#34; href=&#34;https://dl.acm.org/doi/10.1145/3548606.3560604&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;h2 id=&#34;问题引入&#34;&gt;问题引入&lt;/h2&gt;
&lt;p&gt;目前互联网上的流量已被广泛加密，同时流量加密总是被攻击者滥用以隐藏其恶意行为，现有的加密恶意流量检测方法受到监督，它们依赖于已知攻击（例如，标记数据集）的先验知识。&lt;/p&gt;
&lt;h2 id=&#34;提出方法&#34;&gt;提出方法&lt;/h2&gt;
&lt;p&gt;提出了HyperVision，一种基于实时无监督机器学习的恶意流量检测系统。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;能够利用基于流量模式构建的紧凑内存图来检测加密恶意流量的未知模式。该图捕获由图结构特征表示的流交互模式，而不是特定已知攻击的特征。&lt;/li&gt;
&lt;li&gt;我们开发了一种无监督图学习方法，通过分析图的连接性、稀疏性和统计特征来检测异常交互模式&lt;/li&gt;
&lt;li&gt;建立了一个信息论模型来证明图保存的信息接近理想的理论边界。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;h2 id=&#34;现有方法&#34;&gt;现有方法&lt;/h2&gt;
&lt;p&gt;深度数据包检测（DPI）的传统基于签名的方法在加密有效载荷的攻击下无效，加密流量具有与良性流量相似的特征，因此也可以逃避现有的基于机器学习。特别是，现有的加密流量检测方法受到监督，即依赖于已知攻击的先验知识，并且只能检测具有已知流量模式的攻击。此外，这些方法无法检测使用和不使用加密流量构建的攻击，并且由于加密和非加密攻击流量的特征显着不同，因此无法实现通用检测&lt;/p&gt;
&lt;p&gt;简而言之，现有方法无法实现无监督检测，也无法检测具有未知模式的加密恶意流量。特别是，加密的恶意流量具有隐蔽行为，这些方法无法捕获这些行为，这些方法根据单个流的模式检测攻击。但是，检测此类攻击流量仍然是可行的，因为即使攻击的单个流与良性攻击流相似，这些攻击涉及攻击者和受害者之间具有不同流交互的多个攻击步骤与良性流交互模式不同。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1697463380666.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;HyperVision，这是一个实时检测系统，旨在通过分析流之间的交互模式来捕获加密恶意流量的足迹。特别是，它可以通过识别异常流交互（即不同于良性的交互模式）来检测具有未知足迹的加密恶意流。&lt;/p&gt;
&lt;p&gt;但是，构建用于实时检测的图形具有挑战性。我们不能简单地使用 IP 地址作为顶点，而传统的四元组流（源目的ip，源目的port）作为边来构建图，因为生成的密集图无法维持各种流之间的交互模式，例如，引起依赖爆炸问题 。&lt;/p&gt;
&lt;p&gt;收到流量尺寸分布的研究的启发，互联网上的大多数流都是短流，而大多数数据包与长流相关联，我们利用两种策略来记录不同大小的流，并在图中分别处理短流和长流的交互模式。&lt;/p&gt;
&lt;p&gt;我们设计了一种四步 轻量级 无监督 图学习方法，通过利用图上维护的丰富流交互信息来检测加密的恶意流量。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，我们通过提取连通分量来分析图的连通性，并通过对高层次统计特征进行聚类来识别异常分量。通过排除良性分量，我们还显著减少了学习开销。&lt;/li&gt;
&lt;li&gt;其次，我们根据在边特征中观察到的局部邻接关系对边进行预聚类。预聚类操作显著降低了特征处理开销，并确保了实时检测。&lt;/li&gt;
&lt;li&gt;第三，我们使用Z3 SMT solver求解顶点覆盖问题来提取关键顶点，以最大程度地减少聚类的数量。&lt;/li&gt;
&lt;li&gt;最后，根据每个临界顶点的连接边进行聚类，这些边位于预聚类产生的簇的中心，从而得到指示加密恶意流量的异常边。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此外，为了量化HyperVision基于图的流量记录相对于现有方法的优势，我们开发了一个流量记录熵模型，这是一个基于信息论的框架，从理论上分析恶意流量检测系统的现有数据源保留的信息量。这个框架表明NetFlow [19]和Zeek [86]无法保留高保真流量信息，而HyperVision中的图捕获了接近最优的流量信息，并且图中维护的信息量接近理想化数据源的理论上界。（这么屌啊？）此外，分析结果表明，HyperVision中的图形实现了比所有现有数据源更高的信息密度（即每单位存储的流量信息量），这是准确高效检测的基础。&lt;/p&gt;
&lt;p&gt;过两天读R. Zamir, “A proof of the fisher information inequality via a data processing argument,” IEEE Trans. Inf. Theory, vol. 44, no. 3, pp. 12461250, 1998.&lt;/p&gt;
&lt;h2 id=&#34;平台和数据集&#34;&gt;平台和数据集&lt;/h2&gt;
&lt;p&gt;我们使用英特尔的数据平面开发套件 （DPDK） [37] 对 HyperVision进行原型设计。为了广泛评估原型的性能，我们重放了92个攻击数据集，其中包括在我们的虚拟私有云 （VPC）中收集的80个新数据集，其中包含 1,500 多个实例。在 VPC 中，我们收集了 48 个典型的加密恶意流量，包括 （i） 加密泛洪流量，例如泛洪目标链路 [41];（ii） 网络攻击，例如利用网络漏洞 [64];（iii） 恶意软件活动，包括连接测试、依赖项更新和下载。&lt;/p&gt;
&lt;p&gt;此外，HyperVision 的平均检测吞吐量超过 100 Gb/s，平均检测延迟为 0.83 秒。&lt;/p&gt;
&lt;h2 id=&#34;省流&#34;&gt;省流&lt;/h2&gt;
&lt;p&gt;• 我们提出了 HyperVision，这是首个使用流交互图实现对未知模式的加密恶意流量进行实时无监督检测的方法。
• 我们开发了多种算法来构建内存中的图，使我们能够准确捕获不同流之间的交互模式。
• 我们设计了一种轻量级的无监督图形学习方法，通过图形特征来检测加密流量。
• 我们开发了一个由信息论建立的理论分析框架，以展示该图形捕获了接近最优的流量交互信息。
• 我们原型化了 HyperVision，并进行了广泛的实验，使用各种真实世界的加密恶意流量来验证其准确性和效率。&lt;/p&gt;
&lt;h2 id=&#34;名词解释&#34;&gt;名词解释&lt;/h2&gt;
&lt;p&gt;连通分量：在图论中，连通分量是一个图中的一个子图，其中任意两个顶点都可以通过边相连的路径相互访问。&lt;/p&gt;
&lt;p&gt;Z3 SMT solver：3（Z3 SMT solver）是由微软研究院开发的一个高性能的SMT（Satisfiability Modulo Theories）求解器。SMT 求解器是一种自动化工具，用于解决布尔公式、一阶逻辑公式和其他数学理论的判定问题。Z3 在各种计算机科学和工程领域都有广泛的应用，包括软件验证、形式化方法、人工智能、编译器优化和硬件验证等。&lt;/p&gt;
&lt;p&gt;英特尔的数据平面开发套件 （DPDK）：旨在优化数据包处理性能。它专注于高性能网络应用程序和数据平面开发，使开发人员能够在通用服务器硬件上实现高吞吐量和低延迟的数据包处理。它通过绕过操作系统内核，并在用户空间中实现网络协议栈，从而提供极低的延迟和高吞吐量。支持多核处理器，允许并行处理大量数据包。利用支持硬件加速的网络接口卡（NIC）来进一步提高性能。DPDK 是一个开源项目，开发人员可以根据其需求进行自定义和扩展。DPDK 通常用于构建高性能网络应用程序，如网络功能虚拟化（NFV）、防火墙、负载均衡、数据包过滤和路由等。它还用于云计算、边缘计算和网络设备。&lt;/p&gt;
&lt;h1 id=&#34;hypervision&#34;&gt;HyperVision&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://pillar23.github.io/images/1698218520903.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1698218520903&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;首先HyperVision以镜像来的路由器流量作为输入，确保不会干扰流量转发。在识别加密的恶意流量后，它可以与现有的中间恶意流量防御配合，以限制检测到的流量。重点检测使用加密流量构建的主动攻击。不考虑不会为受害者带来流量的被动攻击，例如流量窃听和被动流量分析&lt;/p&gt;
&lt;p&gt;HyperVision的设计目标如下：首先，它应该能够实现通用检测，即检测使用加密或非加密流量构建的攻击，从而确保攻击无法逃避流量加密的检测。其次，它能够实现实时高速流量处理，这意味着它可以识别通过加密流量是否是恶意的，同时产生低检测延迟。第三，HyperVision 执行的检测是不受监督的，这意味着它不需要任何加密恶意流量的先验知识。&lt;/p&gt;
&lt;h2 id=&#34;图构造&#34;&gt;图构造&lt;/h2&gt;
&lt;p&gt;将流分为短流和长流，并分别记录它们的相互作用模式，以降低图的密度。&lt;/p&gt;
&lt;p&gt;使用不同的地址作为顶点，分别连接与短流和长流关联的边。聚合大量相似的短流，为一组短流构建一条边，从而减少维护流交互模式的开销。拟合长流中数据包特征的分布，构建与长流相关的边缘，从而保证了高保真记录的流交互模式，同时解决了传统方法中粗粒度流特征的问题。&lt;/p&gt;
&lt;h2 id=&#34;预处理图&#34;&gt;预处理图&lt;/h2&gt;
&lt;p&gt;通过提取连通分量来减少图的开销，并使用高级统计信息进行聚类。其中，聚类可以准确地检测出只有良性交互模式的组件，从而对这些良性组件进行过滤，减小图的规模。此外，我们进行了预聚类，并使用生成的聚类中心来表示图像中的识别的集群的边缘。（第五节详细讲）&lt;/p&gt;
&lt;h2 id=&#34;基于图的恶意流量检测&#34;&gt;基于图的恶意流量检测&lt;/h2&gt;
&lt;p&gt;通过分析图特征来实现无监督加密恶意流量检测。&lt;/p&gt;
&lt;h1 id=&#34;图构造-1&#34;&gt;图构造&lt;/h1&gt;
&lt;h2 id=&#34;流的分类&#34;&gt;流的分类&lt;/h2&gt;
&lt;p&gt;为了避免图构建过程中流之间的依赖爆炸，把流分成长流和短流，并且降低密度。下图显示了显示了2020年1月MAWI互联网流量数据集的流完成时间和流长度的分布，纵轴PDF是概率密度函数，可以看到不论是长流还是短流都在分布短时间、长长度更多。
&lt;img src=&#34;https://pillar23.github.io/images/1698331144407.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1698331144407&#34;
	
	
&gt;
利用短流合并后，图的稠密度显著下降
&lt;img src=&#34;https://pillar23.github.io/images/1698332038326.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1698332038326&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;获取每个数据包的信息，并获取其源、目标地址、端口号和每个数据包的功能，包括协议、长度和到达间隔。我们开发了一种流量分类算法来对流量进行分类（附录A中的算法1）简单来说就是维护一个哈希表，键是hash(src,dest,src_post,dest_port)，值是流的所有数据包特征的序列(协议、数据包长度、到达间隔)，然后用一个定时器TIME_NOW，每隔JUDGE_INTERVAL检查一下，如果在这个interval里流发了多个数据包，就算他是长流，否则就说他是短流）【q，这个interval怎么设置？为什么后面说ssh暴力破解都是短流？这不是应该是短期发好多包吗？】&lt;/p&gt;
&lt;h2 id=&#34;短流聚合&#34;&gt;短流聚合&lt;/h2&gt;
&lt;p&gt;我们观察到，大多数短流具有几乎相同的每个数据包的特征序列。我们设计了一种聚合短流的算法（附录A中的算法2）。当满足以下所有要求时，可以聚合一组流&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;流具有相同的源和/或目标地址（为啥不是哈希表的键值一样）&lt;/li&gt;
&lt;li&gt;流具有相同的协议类型&lt;/li&gt;
&lt;li&gt;流的数量足够大，即当短流量的数量达到阈值AGG_LINE&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们为短流构建一条边，为所有流及其四个元组保留一个特征序列（即协议、数据包长度和到达间隔）&lt;/p&gt;
&lt;h2 id=&#34;长流的特征分布拟合&#34;&gt;长流的特征分布拟合&lt;/h2&gt;
&lt;p&gt;由于长流中的特征是集中分布的，我们使用直方图来表示长流中每个数据包特征的频率分布。直方图的每个条目表示一个数据包特征的频率，从而避免保留其长的每个数据包特征序列。具体来说，我们为每个长流中的每个数据包特征序列构建直方图，然后维护一个哈希表，    键为数据包特征序列，值为直方图。我们将数据包长度和到达间隔的桶宽度分别设置为 10 字节和 1 毫秒，以在拟合精度和开销之间进行权衡。
下图显示了数据集中的长流中已用桶的数量和最大桶的大小，可以看是集中分布的，即长流中的大多数数据包具有相似的包长度和到达间隔。长度拟合平均用11个桶，每个桶平均200个数据包；到达间隔拟合平均用121个桶，每个桶平均71个数据包。
&lt;img src=&#34;https://pillar23.github.io/images/1698336076628.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1698336076628&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
